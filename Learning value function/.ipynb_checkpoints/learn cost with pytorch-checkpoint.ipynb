{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import crocoddyl as c\n",
    "import numdifftools as nd\n",
    "c.switchToNumpyArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cost\n",
    "positions = []\n",
    "cost = []\n",
    "model = c.ActionModelUnicycle()\n",
    "\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "    T = 30\n",
    "    problem = c.ShootingProblem(x0.T, [ model ] * T, model)\n",
    "    ddp = c.SolverDDP(problem)\n",
    "    ddp.solve()\n",
    "\n",
    "    \n",
    "    positions.append(x0)\n",
    "    cost.append(np.array([ddp.cost]))\n",
    "\n",
    "positions = np.asarray(positions)\n",
    "cost = np.asarray(cost)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.as_tensor(positions, device = device, dtype = torch.float32)\n",
    "y_train = torch.as_tensor(cost, device = device, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(3, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "#net.cuda()\n",
    "net = net.float()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "def weights_init_normal(m):\n",
    "    '''Takes in a module and initializes all linear layers with weight\n",
    "       values taken from a normal distribution.'''\n",
    "\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model\n",
    "    if classname.find('Linear') != -1:\n",
    "        y = m.in_features\n",
    "    # m.weight.data shoud be taken from a normal distribution\n",
    "        m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
    "    # m.bias.data should be 0\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "net.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    #total_loss = 0\n",
    "    for inputs, target in zip(x_train, y_train):   \n",
    "        optimizer.zero_grad()\n",
    "        y_hat = net(x_train.float())\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #total_loss += loss.item()\n",
    "    #print(\"Epoch : \", epoch , \"Loss : \", total_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2m(a):\n",
    "    return np.matrix(a).T\n",
    "\n",
    "def m2a(m):\n",
    "    return np.array(m).squeeze()\n",
    "\n",
    "\n",
    "c.switchToNumpyMatrix()\n",
    "class UnicycleTerminal(c.ActionModelAbstract):\n",
    "    def __init__(self, cost, lx, lxx):\n",
    "        c.ActionModelAbstract.__init__(self, c.StateVector(3), 2, 5)\n",
    "        self.cost = cost\n",
    "        self.lx = lx\n",
    "        self.lxx = lxx\n",
    "        \n",
    "        \n",
    "    def calc(self, data, x, u=None):        \n",
    "        data.cost = self.cost\n",
    "            \n",
    "        \n",
    "    def calcDiff(self, data, x, u=None, recalc=True):\n",
    "        if u is None:\n",
    "            u = self.unone\n",
    "        if recalc:\n",
    "            self.calc(data, x, u)\n",
    "            \n",
    "        data.Lx = self.lx\n",
    "        data.Lxx = self.lxx\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = net.fc1.weight.data.cpu().numpy()\n",
    "b1 = net.fc1.bias.data.cpu().numpy()\n",
    "\n",
    "w2 = net.fc2.weight.data.cpu().numpy()\n",
    "b2 = net.fc2.bias.data.cpu().numpy()\n",
    "\n",
    "w3 = net.fc3.weight.data.cpu().numpy()\n",
    "b3 = net.fc3.bias.data.cpu().numpy()\n",
    "\n",
    "def value_function(y):\n",
    "    out1 = np.tanh(y.dot(w1.T) + b1)\n",
    "    out2 = np.tanh(out1.dot(w2.T) + b2)\n",
    "    out3 = out2.dot(w3.T) + b3\n",
    "    \n",
    "    return out3\n",
    "\n",
    "j = nd.Jacobian(value_function)\n",
    "h = nd.Hessian(value_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441.9880676269531 984.6124323667799\n",
      "441.9880676269531 1357.134989352498\n",
      "441.9880676269531 1215.2737078100658\n",
      "441.9880676269531 444.8051725800973\n",
      "441.9880676269531 1165.5644261785594\n",
      "441.9880676269531 917.362850435374\n",
      "441.9880676269531 1198.170112704945\n",
      "441.9880676269531 1338.5674010218877\n",
      "441.9880676269531 1468.2752816801956\n",
      "441.9880676269531 1012.9699018350611\n"
     ]
    }
   ],
   "source": [
    "model = c.ActionModelUnicycle()\n",
    "start = perf_counter()\n",
    "for _ in range(10):\n",
    "    \n",
    "    x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "    x = torch.as_tensor(x0.reshape(1, -1), device = device, dtype = torch.float32)\n",
    "    cost = float(net(x).view(1, 1))\n",
    "    lx = a2m(j(x0))\n",
    "    lxx = a2m(h(x0))\n",
    "    \n",
    "    terminal_model = UnicycleTerminal(cost, lx, lxx)\n",
    "    T = 30\n",
    "    problem = c.ShootingProblem(x0.T, [ model ] * T, terminal_model)\n",
    "    ddp = c.SolverDDP(problem)\n",
    "    ddp.solve([], [], 1000)\n",
    "    print(cost, ddp.cost)\n",
    "end = perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "x = torch.as_tensor(x0.reshape(1, -1), device = device, dtype=torch.float32)\n",
    "x.requires_grad=True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amit/.local/lib/python3.6/site-packages/torch/autograd/gradcheck.py:242: UserWarning: At least one of the inputs that requires gradient is not of double precision floating point. This check will likely fail if all the inputs are not of double precision floating point. \n",
      "  'At least one of the inputs that requires gradient '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.gradcheck(net, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
