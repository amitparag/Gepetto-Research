{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, recall where this approximation H≈JTJ comes from. Let (xi,yi) be your data points, f(⋅) be your model and β be the parameters of your model. Then the objective function of the non-linear least squares problem is 12rTr where r is the vector of the residuals, ri=yi−f(xi,β). The exact Hessian of the objective function is H=JTJ+∑ri∇2ri. So the error in this approximation is H−JTJ=∑ri∇2ri. It's a good approximation when the residuals, themselves, are small; or when the 2nd derivative of the residuals is small. Linear least squares can be considered a special case where the 2nd derivative of the residuals is zero.\n",
    "\n",
    "As for finite difference approximation, it is relatively cheap. To compute a central difference, you'll need to evaluate the Jacobian an additional 2n times (a forward difference will cost you n additional evaluations, so I wouldn't bother). The error of the central difference approximation is proportional to ∇4r and h2, where h is the step size. The optimal step size is h∼ϵ13, where ϵ is machine precision. So unless the derivatives of the residuals are blowing up, it's pretty clear that the finite difference approximation should be a LOT better. I should point out that, while the computation is minimal, the bookkeeping is nontrivial. Each finite difference on the Jacobian will give you one row of the Hessian for each residual. You'll then have to reassemble the Hessian using the formula above.\n",
    "\n",
    "There is, however, a 3rd option. If your solver uses a Quasi-Newton method (DFP, BFGS, Bryoden, etc.), it is already approximating the Hessian at each iteration. The approximation can be quite good, as it uses the objective function and gradient values from every iteration. Most solvers will give you access to the final Hessian estimate (or its inverse). If that's an option for you, I would use that as the Hessian estimate. It's already computed and it's probably going to be a pretty good estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import crocoddyl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numdifftools as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.5, 1.5, 0.])\n",
    "\n",
    "model = crocoddyl.ActionModelUnicycle()\n",
    "T = 30\n",
    "model.costWeights = np.matrix([1,1]).T\n",
    "\n",
    "problem = crocoddyl.ShootingProblem(x.T, [ model ] * T, model)\n",
    "ddp = crocoddyl.SolverDDP(problem)\n",
    "ddp.solve([], [], 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functions(x):\n",
    "    model = crocoddyl.ActionModelUnicycle()\n",
    "    T = 30\n",
    "    model.costWeights = np.matrix([1,1]).T\n",
    "\n",
    "    problem = crocoddyl.ShootingProblem(x.T, [ model ] * T, model)\n",
    "    ddp = crocoddyl.SolverDDP(problem)\n",
    "    ddp.solve([], [], 1000)\n",
    "    j = np.array(ddp.Vx)\n",
    "    print(type(j[0]))\n",
    "    return j[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ddp.Vx[0]\n",
    "j = j.reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.37797708,  -2.22218284,   4.01606954],\n",
       "       [ -2.22218284,  17.53326374, -11.44757606],\n",
       "       [  4.01606954, -11.44757606,  20.53519374]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = ddp.Vxx[0]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = j @ x.reshape(1, 3)\n",
    "h1 = h1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3092.05709426, 3092.05709426,    0.        ],\n",
       "       [3092.05709426, 3092.05709426,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 @ h1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15.81506233,  15.81506233,   0.        ],\n",
       "       [ 45.60781658,  45.60781658,   0.        ],\n",
       "       [-27.60195581, -27.60195581,   0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
