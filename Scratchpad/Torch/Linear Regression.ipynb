{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1) (11, 1)\n",
      "tensor(272.3192, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 272.3192443847656\n",
      "tensor(22.2482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 22.248207092285156\n",
      "tensor(1.8503, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 1.850308895111084\n",
      "tensor(0.1861, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 0.1861186921596527\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 0.04998316243290901\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 0.03849027305841446\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 0.0371684804558754\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 0.03668071702122688\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 0.036265164613723755\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 0.03585975989699364\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 0.035459257662296295\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 0.03506329655647278\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 0.03467179834842682\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 0.034284573048353195\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 0.033901698887348175\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 0.03352311998605728\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 0.03314879536628723\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 0.03277863189578056\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 0.03241262584924698\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 0.03205068036913872\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 0.0316927507519722\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 0.031338803470134735\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 0.0309889055788517\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 0.030642835423350334\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 0.03030063770711422\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 0.029962291941046715\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 0.029627695679664612\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 0.029296867549419403\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 0.028969701379537582\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 0.028646185994148254\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 0.028326302766799927\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 0.02800995670258999\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 0.027697211131453514\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 0.027387874200940132\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 0.027082102373242378\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 0.026779647916555405\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 0.026480596512556076\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 0.026184914633631706\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 0.025892486795783043\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 0.02560335025191307\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 0.025317424908280373\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 0.025034725666046143\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 0.024755161255598068\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 0.02447865903377533\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 0.024205371737480164\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 0.02393502928316593\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 0.02366775833070278\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 0.023403506726026535\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 0.023142140358686447\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 0.02288374863564968\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 0.022628197446465492\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 0.02237551100552082\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 0.022125637158751488\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 0.021878564730286598\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 0.021634256467223167\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 0.02139265276491642\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 0.02115379273891449\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 0.020917575806379318\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 0.02068397030234337\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 0.020452989265322685\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 0.020224621519446373\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 0.019998779520392418\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 0.019775424152612686\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 0.019554587081074715\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 0.01933622546494007\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 0.019120320677757263\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 0.018906759098172188\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 0.018695661798119545\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 0.018486883491277695\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 0.01828044466674328\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 0.018076300621032715\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 0.017874419689178467\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 0.017674844712018967\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 0.017477473244071007\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 0.017282288521528244\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 0.017089322209358215\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 0.0168985053896904\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 0.016709785908460617\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 0.016523201018571854\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 0.016338661313056946\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 0.016156233847141266\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 0.01597583293914795\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 0.015797410160303116\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 0.015620989724993706\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 0.0154465576633811\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 0.015274062752723694\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 0.015103494748473167\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 0.014934845268726349\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 0.01476810872554779\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 0.014603178948163986\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 0.014440092258155346\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 0.01427884865552187\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 0.01411938201636076\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 0.013961730524897575\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 0.013805799186229706\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 0.013651655986905098\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 0.013499200344085693\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 0.013348458334803581\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 0.013199388980865479\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 0.013051994144916534\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype = np.float32).reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values ]\n",
    "y_train = np.array(y_values, dtype = np.float32).reshape(-1, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputsize, outputsize):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputsize, outputsize)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    \n",
    "inputDim = 1        # takes variable 'x' features of x\n",
    "outputDim = 1       # takes variable 'y' features of y\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "\n",
    "model = LinearRegression(inputDim, outputDim)\n",
    "##### For GPU #######\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-80afea7fb9e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "reduce((lambda x: sum(x **2)), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b  = torch.rand((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.dist(b, b, p=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
