{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import crocoddyl as c\n",
    "import numdifftools as nd\n",
    "from time import perf_counter\n",
    "c.switchToNumpyArray()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cost\n",
    "positions = []\n",
    "cost = []\n",
    "model = c.ActionModelUnicycle()\n",
    "\n",
    "start = perf_counter()\n",
    "for _ in range(2000):\n",
    "    \n",
    "    x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "    T = 30\n",
    "    problem = c.ShootingProblem(x0.T, [ model ] * T, model)\n",
    "    ddp = c.SolverDDP(problem)\n",
    "    ddp.solve()\n",
    "\n",
    "    \n",
    "    positions.append(x0)\n",
    "    cost.append(np.array([ddp.cost]))\n",
    "end = perf_counter()\n",
    "positions = np.asarray(positions)\n",
    "cost = np.asarray(cost)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.as_tensor(positions[0:1000, :], device = device, dtype = torch.float32)\n",
    "y_train = torch.as_tensor(cost[0:1000, :], device = device, dtype = torch.float32)\n",
    "\n",
    "x_valid = torch.as_tensor(positions[1000:,:], device = device, dtype = torch.float32)\n",
    "y_valid = torch.as_tensor(cost[1000:,:], device = device, dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_features, 16)\n",
    "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "        self.fc1.bias.data.fill_(0.0)\n",
    "        \n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
    "        self.fc2.bias.data.fill_(0.0)\n",
    "        \n",
    "        self.fc3 = nn.Linear(16, output_features)\n",
    "        torch.nn.init.xavier_normal_(self.fc3.weight)\n",
    "        self.fc3.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(x_train.shape[1], y_train.shape[1])\n",
    "net = net.float()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(150):\\n    net.train()\\n    #total_loss = 0\\n    for inputs, target in zip(x_train, y_train):   \\n        optimizer.zero_grad()\\n        y_hat = net(inputs)\\n        loss = criterion(y_hat, target)\\n        loss.backward()\\n        optimizer.step()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for epoch in range(150):\n",
    "    net.train()\n",
    "    #total_loss = 0\n",
    "    for inputs, target in zip(x_train, y_train):   \n",
    "        optimizer.zero_grad()\n",
    "        y_hat = net(inputs)\n",
    "        loss = criterion(y_hat, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\"\"\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 150 \n",
    "batch_size = 4 \n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(x_train.size()[0])\n",
    "\n",
    "    for i in range(0,x_train.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x_train[indices], y_train[indices]\n",
    "\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = net(batch_x)\n",
    "        loss = criterion(outputs,batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "x = torch.as_tensor(x0.reshape(1, -1), device = device, dtype = torch.float32)\n",
    "x.requires_grad = True\n",
    "\n",
    "def pytorch_output(x):\n",
    "    return net(x)\n",
    "\n",
    "\n",
    "def jacobian(y, x, create_graph=False):                                                               \n",
    "    jac = []                                                                                          \n",
    "    flat_y = y.reshape(-1)                                                                            \n",
    "    grad_y = torch.zeros_like(flat_y)                                                                 \n",
    "    for i in range(len(flat_y)):                                                                      \n",
    "        grad_y[i] = 1.                                                                                \n",
    "        grad_x, = torch.autograd.grad(flat_y, x, grad_y, retain_graph=True, create_graph=create_graph)\n",
    "        jac.append(grad_x.reshape(x.shape))                                                           \n",
    "        grad_y[i] = 0.                                                                                \n",
    "    return torch.stack(jac).reshape(y.shape + x.shape)                                                \n",
    "                                                                                                      \n",
    "def hessian(y, x):                                                                                    \n",
    "    return jacobian(jacobian(y, x, create_graph=True), x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[429.6963]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pytorch_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.]]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(net(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[[0., 0., 0.]],\n",
       "\n",
       "           [[0., 0., 0.]],\n",
       "\n",
       "           [[0., 0., 0.]]]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessian(net(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9160, -1.9770,  0.7249]], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
