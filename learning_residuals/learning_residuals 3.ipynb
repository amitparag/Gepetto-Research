{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import crocoddyl as c\n",
    "import numdifftools as nd\n",
    "c.switchToNumpyArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the residual data\n",
    "positions = []\n",
    "residuals = []\n",
    "model = c.ActionModelUnicycle()\n",
    "\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "    T = 30\n",
    "    problem = c.ShootingProblem(x0.T, [ model ] * T, model)\n",
    "    ddp = c.SolverDDP(problem)\n",
    "    ddp.solve()\n",
    "\n",
    "    for d in ddp.datas():\n",
    "        residual = d.r\n",
    "    positions.append(x0)\n",
    "    residuals.append(residual)\n",
    "\n",
    "positions = np.asarray(positions)\n",
    "residuals = np.asarray(residuals)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.as_tensor(positions, device = device, dtype = torch.float32)\n",
    "y_train = torch.as_tensor(residuals, device = device, dtype = torch.float32)\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(3, 8)\n",
    "        self.fc2 = nn.Linear(8, 8)\n",
    "        self.fc3 = nn.Linear(8, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "net = net.float()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "def weights_init_normal(m):\n",
    "    '''Takes in a module and initializes all linear layers with weight\n",
    "       values taken from a normal distribution.'''\n",
    "\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model\n",
    "    if classname.find('Linear') != -1:\n",
    "        y = m.in_features\n",
    "    # m.weight.data shoud be taken from a normal distribution\n",
    "        m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
    "    # m.bias.data should be 0\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "net.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    #total_loss = 0\n",
    "    for inputs, target in zip(x_train, y_train):   \n",
    "        optimizer.zero_grad()\n",
    "        y_hat = net(x_train.float())\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #total_loss += loss.item()\n",
    "    #print(\"Epoch : \", epoch , \"Loss : \", total_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2m(a):\n",
    "    return np.matrix(a).T\n",
    "\n",
    "def m2a(m):\n",
    "    return np.array(m).squeeze()\n",
    "c.switchToNumpyMatrix()\n",
    "class UnicycleTerminal(c.ActionModelAbstract):\n",
    "    def __init__(self, r, cost):\n",
    "        c.ActionModelAbstract.__init__(self, c.StateVector(3), 2, 5)\n",
    "        self.r = r\n",
    "        self.cost = cost\n",
    "        self.dt = .1\n",
    "        self.costWeights = [10., 1.]\n",
    "        \n",
    "    def calc(self, data, x, u=None):\n",
    "        data.r = self.r\n",
    "        data.cost = self.cost\n",
    "            \n",
    "        \n",
    "    def calcDiff(self, data, x, u=None, recalc=True):\n",
    "        if u is None:\n",
    "            u = self.unone\n",
    "        if recalc:\n",
    "            self.calc(data, x, u)\n",
    "\n",
    "        v, w = m2a(u)\n",
    "        px, py, theta = m2a(x)\n",
    "        # Cost derivatives\n",
    "        data.Lx = a2m(m2a(x) * ([self.costWeights[0]**2] * self.state.nx))\n",
    "        data.Lu = a2m(m2a(u) * ([self.costWeights[1]**2] * self.nu))\n",
    "        data.Lxx = np.diag([self.costWeights[0]**2] * self.state.nx)\n",
    "        data.Luu = np.diag([self.costWeights[1]**2] * self.nu)\n",
    "        # Dynamic derivatives\n",
    "        c, s, dt = np.cos(theta), np.sin(theta), self.dt\n",
    "        v, w = m2a(u)\n",
    "        data.Fx = np.matrix([[1, 0, -s * v * dt], [0, 1, c * v * dt], [0, 0, 1]])\n",
    "        data.Fu = np.matrix([[c * self.dt, 0], [s * self.dt, 0], [0, self.dt]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006832639686763287\n",
      "289.97471583473055\n",
      "0.15769615769386292\n",
      "820.9182095273733\n",
      "0.17169751226902008\n",
      "435.67316735974066\n",
      "0.19839900732040405\n",
      "534.5062136411034\n",
      "0.1414482444524765\n",
      "440.34663534356605\n",
      "0.1753014475107193\n",
      "624.7543022204886\n",
      "0.162895068526268\n",
      "929.5148985039737\n",
      "0.1529536247253418\n",
      "170.36758265973688\n",
      "0.1739140897989273\n",
      "729.3758044350878\n",
      "0.09297199547290802\n",
      "627.7124009502083\n",
      "0.07953260093927383\n",
      "193.75965637152265\n",
      "0.1942114531993866\n",
      "500.95008538559017\n",
      "0.1990814357995987\n",
      "266.8373987559319\n",
      "0.191854327917099\n",
      "470.4791005802483\n",
      "2.0836983821936883e-05\n",
      "567.5560755127806\n",
      "0.1648905724287033\n",
      "994.7830586889813\n",
      "0.17051434516906738\n",
      "787.3189361702559\n",
      "0.21959547698497772\n",
      "198.56497761020537\n",
      "0.15425559878349304\n",
      "520.6484657182333\n",
      "0.22920012474060059\n",
      "184.88274262712494\n",
      "0.17786835134029388\n",
      "534.5361924999154\n",
      "0.16885267198085785\n",
      "183.6074357730502\n",
      "0.15959398448467255\n",
      "222.73441200932803\n",
      "0.12886328995227814\n",
      "587.2685069471877\n",
      "0.1780531108379364\n",
      "540.9546894120236\n",
      "0.10768949240446091\n",
      "607.739837734873\n",
      "0.18176794052124023\n",
      "269.23444839805853\n",
      "0.16294343769550323\n",
      "152.98480295202899\n",
      "0.0025609228760004044\n",
      "116.78064428953671\n",
      "0.17845724523067474\n",
      "333.29879075423963\n",
      "0.17565415799617767\n",
      "698.3892799186092\n",
      "0.18588361144065857\n",
      "84.31992478420052\n",
      "0.16108907759189606\n",
      "737.9778989705756\n",
      "0.1006583720445633\n",
      "1216.0858548148442\n",
      "0.12593844532966614\n",
      "130.26846577948044\n",
      "0.1269976943731308\n",
      "1036.852121926403\n",
      "0.16971956193447113\n",
      "334.4025779600532\n",
      "0.10956994444131851\n",
      "291.6730802096458\n",
      "0.02698972448706627\n",
      "299.30822783666076\n",
      "0.1372980773448944\n",
      "847.2258814358673\n",
      "0.16381536424160004\n",
      "499.99950360671676\n",
      "0.14018577337265015\n",
      "439.84839212930643\n",
      "0.20927007496356964\n",
      "252.75750842216786\n",
      "0.15935732424259186\n",
      "926.0987701640425\n",
      "0.1832597553730011\n",
      "528.0485609610414\n",
      "0.1126890629529953\n",
      "292.1948056833513\n",
      "0.05839429423213005\n",
      "286.6188383827963\n",
      "0.21425917744636536\n",
      "257.3914558560547\n",
      "0.1756807118654251\n",
      "344.3876931920825\n",
      "0.17066295444965363\n",
      "443.4749174659302\n",
      "0.01497578714042902\n",
      "78.61317593959649\n",
      "0.20712263882160187\n",
      "327.5323493114711\n",
      "0.11206807941198349\n",
      "584.6075157797904\n",
      "0.11932586133480072\n",
      "421.309290549719\n",
      "0.08920882642269135\n",
      "527.6207212030862\n",
      "0.14447133243083954\n",
      "123.50813045423916\n",
      "0.20800134539604187\n",
      "315.3737439975595\n",
      "0.10145974159240723\n",
      "670.0235368997936\n",
      "0.15798068046569824\n",
      "376.6934381606889\n",
      "0.21495528519153595\n",
      "250.87632293561052\n",
      "0.09565968066453934\n",
      "233.68456137280435\n",
      "0.17042817175388336\n",
      "818.9137873155084\n",
      "0.1498163342475891\n",
      "597.929459429393\n",
      "0.16410261392593384\n",
      "204.18166975976402\n",
      "0.21609945595264435\n",
      "128.4770708190784\n",
      "0.16870085895061493\n",
      "406.73424574552354\n",
      "0.11381973326206207\n",
      "120.66817544628762\n",
      "0.0896088257431984\n",
      "303.1417438000107\n",
      "0.17765550315380096\n",
      "702.4422028645544\n",
      "0.17959563434123993\n",
      "599.2161668496128\n",
      "0.18032053112983704\n",
      "696.7414753615017\n",
      "0.21581338346004486\n",
      "168.59915974423234\n",
      "0.17781856656074524\n",
      "660.5110016657791\n",
      "0.2053292840719223\n",
      "382.09223751435326\n",
      "0.12302793562412262\n",
      "653.5290189972872\n",
      "0.13630454242229462\n",
      "396.8130607343714\n",
      "7.231454219436273e-05\n",
      "295.034530711716\n",
      "0.14025790989398956\n",
      "350.87976773480557\n",
      "0.21048519015312195\n",
      "143.68551044459434\n",
      "0.001647486351430416\n",
      "213.28469067763803\n",
      "0.18921391665935516\n",
      "223.71483949815195\n",
      "0.1699458658695221\n",
      "797.3390596014989\n",
      "0.1716453582048416\n",
      "384.6686893396357\n",
      "0.10664200782775879\n",
      "326.67819291583635\n",
      "0.13830158114433289\n",
      "571.6771928151226\n",
      "0.17018453776836395\n",
      "463.9371945525606\n",
      "0.20746369659900665\n",
      "177.88922847288967\n",
      "0.2100365161895752\n",
      "180.56790238863255\n",
      "0.20324937999248505\n",
      "140.0039556028861\n",
      "0.20744504034519196\n",
      "324.98400697841356\n",
      "0.1968926042318344\n",
      "578.162490477483\n",
      "0.14117984473705292\n",
      "317.3041085723161\n",
      "0.1625691056251526\n",
      "494.55427670123765\n",
      "0.1410924643278122\n",
      "623.4345125293295\n",
      "0.21061530709266663\n",
      "301.2728208915164\n",
      "0.19850212335586548\n",
      "401.5722515874208\n",
      "0.16615355014801025\n",
      "214.9402987833098\n",
      "0.16599707305431366\n",
      "872.5554443545407\n",
      "0.12555727362632751\n",
      "303.6151757600128\n",
      "0.15503177046775818\n",
      "842.7490949497114\n"
     ]
    }
   ],
   "source": [
    "model = c.ActionModelUnicycle()\n",
    "start = perf_counter()\n",
    "for _ in range(100):\n",
    "    x0 = np.array([np.random.uniform(-2.1, 2.1), np.random.uniform(-2.1, 2.1), np.random.uniform(0,1)])\n",
    "    x = torch.as_tensor(x0.reshape(1, -1), device = device, dtype = torch.float32)\n",
    "    prediction = net(x).view(5, 1)\n",
    "    r_ = prediction.cpu()\n",
    "    r = r_.detach().numpy()\n",
    "    cost = 0.5 * float(torch.matmul(prediction.T, prediction))\n",
    "    print(cost)\n",
    "    terminal_model = UnicycleTerminal(r, cost)\n",
    "    T = 30\n",
    "    problem = c.ShootingProblem(x0.T, [ model ] * T, terminal_model)\n",
    "    ddp = c.SolverDDP(problem)\n",
    "    ddp.solve([], [], 1000)\n",
    "    print(ddp.cost)\n",
    "end = perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.36551141399832\n"
     ]
    }
   ],
   "source": [
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
