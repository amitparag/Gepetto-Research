{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "# Plot gradient norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import crocoddyl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from feedforwardnet import FNet, jacobian, hessian\n",
    "from utils import solve_crocoddyl, random_array, griddata\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('fnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = griddata(70)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crocoddyl_gradient_norms(xtest):\n",
    "    solutions = []\n",
    "    for xyz in xtest:\n",
    "        ddp = solve_crocoddyl(xyz)\n",
    "        solutions.append(ddp)\n",
    "\n",
    "\n",
    "    vx    = []\n",
    "    vxx   = []\n",
    "    cost  = []\n",
    "\n",
    "\n",
    "    for ddp in solutions:\n",
    "\n",
    "        diff1  = np.array(ddp.Vx)\n",
    "        diff2  = np.array(ddp.Vxx)\n",
    "\n",
    "        vx.append([np.linalg.norm(diff1[0])])\n",
    "        vxx.append([np.linalg.norm(diff2[0])])\n",
    "\n",
    "        cost.append([ddp.cost])\n",
    "\n",
    "\n",
    "\n",
    "    vx    = np.array(vx).reshape(-1, 1)\n",
    "    vxx   = np.array(vxx).reshape(-1, 1)\n",
    "    cost  = np.array(cost).reshape(-1,1)\n",
    "    return cost, vx, vxx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_gradient_norms(net, xtest):\n",
    "    cost = net(torch.tensor(xtest, dtype=torch.float32)).detach().numpy().reshape(-1,1)\n",
    "    \n",
    "    true_gradient      = []\n",
    "    approx_hessian     = []\n",
    "    true_hessian       = []\n",
    "\n",
    "    states = torch.tensor(xtest, dtype=torch.float32)\n",
    "    \n",
    "    for state in states:\n",
    "        \n",
    "        state.requires_grad = True\n",
    "        \n",
    "        # True gradient\n",
    "        grad = jacobian(net(state), state)\n",
    "        true_gradient.append(np.linalg.norm(grad.detach().numpy()))\n",
    "        #print(grad)\n",
    "        \n",
    "        # True Hessian\n",
    "        _hessian = hessian(net(state), state).detach().numpy()\n",
    "        true_hessian.append(np.linalg.norm(_hessian))\n",
    "        #print(_hessian)\n",
    "        \n",
    "        # Estimating from Jacobian\n",
    "        newton = grad.T @ grad\n",
    "        newton_hessian = newton.detach().numpy()\n",
    "        approx_hessian.append(np.linalg.norm(newton_hessian))\n",
    "\n",
    "        \n",
    "    true_gradient    =  np.array(true_gradient).reshape(-1, 1)\n",
    "    true_hessian     =  np.array(true_hessian).reshape(-1,1)\n",
    "    approx_hessian   =  np.array(approx_hessian).reshape(-1, 1)\n",
    "    \n",
    "    return cost, true_gradient, true_hessian, approx_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corresponding predictions for vx and vxx and cost from squared net\n",
    "\n",
    "cost_pred, net_gradient, net_hessian, net_approx_hessian = network_gradient(net, xtest)\n",
    "\n",
    "cost, vx, vxx = crocoddyl_gradient(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Make the figure:\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(18, 20), sharex=True, sharey ='row')\n",
    "fig.subplots_adjust(left=0.02, bottom=0.2, right=0.95, top=0.94, wspace=0.25)\n",
    "\n",
    "# Plot prediction, cost\n",
    "im1 = axs[0, 0].scatter(x = xtest[:,0], y = xtest[:,1], c= cost_pred)\n",
    "fig.colorbar(im1, ax=axs[0, 0])\n",
    "\n",
    "\n",
    "im2 = axs[0, 1].scatter(x = xtest[:,0], y = xtest[:,1], c= cost)\n",
    "fig.colorbar(im2, ax=axs[0, 1])\n",
    "\n",
    "\n",
    "\n",
    "im3 = axs[1, 0].scatter(x = xtest[:,0], y = xtest[:,1], c=  net_gradient)\n",
    "fig.colorbar(im3, ax=axs[1, 0])\n",
    "\n",
    "im4 = axs[1, 1].scatter(x = xtest[:,0], y = xtest[:,1], c=  vx)\n",
    "fig.colorbar(im4, ax=axs[1, 1])\n",
    "\n",
    "\n",
    "im5 = axs[2, 0].scatter(x = xtest[:,0], y = xtest[:,1], c=  net_hessian)\n",
    "fig.colorbar(im5, ax=axs[2, 0])\n",
    "\n",
    "im6 = axs[2, 1].scatter(x = xtest[:,0], y = xtest[:,1], c=  vxx)\n",
    "fig.colorbar(im6, ax=axs[2, 1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set titles\n",
    "axs[0, 0].set_title(\"Predictions, p\", fontsize  = 15)\n",
    "axs[0, 1].set_title(\"Data, v\", fontsize  = 15)\n",
    "\n",
    "axs[1, 0].set_title(\"norm(grad(p))\", fontsize  = 15)\n",
    "axs[1, 1].set_title(\"norm(Vx)\", fontsize  = 15)\n",
    "axs[2, 0].set_title(\"norm hessian(p)\", fontsize  = 15)\n",
    "axs[2, 1].set_title(\"norm Vxx\", fontsize  = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
