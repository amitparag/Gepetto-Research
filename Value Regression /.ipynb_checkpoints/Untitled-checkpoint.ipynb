{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file neuralNets.py\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_features:int  = 3,\n",
    "                 out_features:int = 1,\n",
    "                 nhiddenunits:int = 256):\n",
    "        \n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.nhiddenunits = nhiddenunits\n",
    "        \n",
    "        # Structure\n",
    "        self.fc1 = nn.Linear(self.in_features, self.nhiddenunits)\n",
    "        self.fc2 = nn.Linear(self.nhiddenunits, 3)\n",
    "        self.fc3 = nn.Linear(3, self.out_features)\n",
    "\n",
    "        # Weight Initialization protocol\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "        \n",
    "        # Bias Initialization protocol\n",
    "        self.fc1.bias.data.fill_(0)\n",
    "        self.fc2.bias.data.fill_(0)\n",
    "        self.fc3.bias.data.fill_(0)\n",
    "        \n",
    "        # Activation\n",
    "        self.activation = nn.Tanh()\n",
    "      \n",
    "        self.device = torch.device('cpu')\n",
    "        self.to(self.device)\n",
    "        print(self)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.activation(self.fc1(x)) \n",
    "        x2 = self.activation(self.fc2(x1)) \n",
    "        x3 = self.fc3(x2) \n",
    "        \n",
    "        return x3\n",
    "    \n",
    "\n",
    "    def jacobian(self, x):\n",
    "        j = torch.autograd.functional.jacobian(self.forward, x).squeeze()\n",
    "        return j\n",
    "\n",
    "    def hessian(self, x):\n",
    "        h = torch.autograd.functional.hessian(self.forward, x).squeeze()\n",
    "        return h\n",
    "\n",
    "    def batch_hessian(self, x):\n",
    "        h = [torch.autograd.functional.hessian(self.forward, x) for x in x]\n",
    "        return torch.stack(h).squeeze()\n",
    "    \n",
    "    def batch_jacobian(self, x):\n",
    "        j = [torch.autograd.functional.jacobian(self.forward, x) for x in x]\n",
    "        return torch.stack(j).squeeze()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_features:int  = 3,\n",
    "                 out_features:int = 3,\n",
    "                 nhiddenunits:int = 256):\n",
    "        \n",
    "        super(SquaredNet, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.nhiddenunits = nhiddenunits\n",
    "        \n",
    "        # Structure\n",
    "        self.fc1 = nn.Linear(self.in_features, self.nhiddenunits)\n",
    "        self.fc2 = nn.Linear(self.nhiddenunits, 3)\n",
    "        self.fc3 = nn.Linear(3, self.out_features)\n",
    "\n",
    "        # Weight Initialization protocol\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "        \n",
    "        # Bias Initialization protocol\n",
    "        self.fc1.bias.data.fill_(0)\n",
    "        self.fc2.bias.data.fill_(0)\n",
    "        self.fc3.bias.data.fill_(0)\n",
    "        \n",
    "        # Activation\n",
    "        self.activation = nn.Tanh()\n",
    "      \n",
    "        self.device = torch.device('cpu')\n",
    "        self.to(self.device)\n",
    "        print(self)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.activation(self.fc1(x)) \n",
    "        x = self.activation(self.fc2(x)) \n",
    "        x = self.fc3(x) \n",
    "        return x\n",
    "    \n",
    "    def value(self, x):\n",
    "        return (sum(self.forward(x) ** 2))\n",
    "    \n",
    "    def batch_value(self, x):\n",
    "        return torch.stack([torch.sum(self.forward(x) ** 2) for x in x]).reshape(-1,1)\n",
    "    \n",
    "\n",
    "    def jacobian(self, x):\n",
    "        j = torch.autograd.functional.jacobian(self.value, x).squeeze()\n",
    "        return j\n",
    "\n",
    "    def hessian(self, x):\n",
    "        h = torch.autograd.functional.hessian(self.value, x).squeeze()\n",
    "        return h\n",
    "\n",
    "    def batch_hessian(self, x):\n",
    "        h = [torch.autograd.functional.hessian(self.value, x) for x in x]\n",
    "        return torch.stack(h).squeeze()\n",
    "    \n",
    "    def batch_jacobian(self, x):\n",
    "        j = [torch.autograd.functional.jacobian(self.value, x) for x in x]\n",
    "        return torch.stack(j).squeeze()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SquaredNet(\n",
      "  (fc1): Linear(in_features=3, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "s = SquaredNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8392,  0.2930,  0.6424],\n",
       "        [ 0.3304,  0.5547, -0.0081],\n",
       "        [-0.9355,  0.7004, -0.5070],\n",
       "        [-0.6448,  0.9430, -0.3993],\n",
       "        [-0.9316,  1.0844, -0.5376],\n",
       "        [ 1.9595, -0.0632,  0.7051],\n",
       "        [-0.1114,  0.1706, -0.1751],\n",
       "        [-1.6299,  0.6247, -0.8139],\n",
       "        [-0.9746,  0.6982, -0.5580],\n",
       "        [ 0.9655,  0.8317,  0.2727]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8814],\n",
       "        [0.4169],\n",
       "        [1.6228],\n",
       "        [1.4645],\n",
       "        [2.3328],\n",
       "        [4.3406],\n",
       "        [0.0722],\n",
       "        [3.7093],\n",
       "        [1.7487],\n",
       "        [1.6982]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.batch_value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1.8392,  0.2930,  0.64241])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8811962481"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(v **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6982, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.value(x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -4.7639,   2.4678,   3.6407],\n",
       "         [  2.4678,  -7.9504,   2.8233],\n",
       "         [  3.6407,   2.8233,  -9.9742]],\n",
       "\n",
       "        [[  2.7489,   1.3203,  -4.2402],\n",
       "         [  1.3203,  18.2887, -16.4158],\n",
       "         [ -4.2402, -16.4158,  17.6424]],\n",
       "\n",
       "        [[ -2.9889,  -3.8744,   8.9914],\n",
       "         [ -3.8744,   1.5212,  -1.7252],\n",
       "         [  8.9914,  -1.7252,  -2.6330]],\n",
       "\n",
       "        [[ -1.5122,  -5.7050,   7.8880],\n",
       "         [ -5.7050,   4.4022,  -2.8847],\n",
       "         [  7.8880,  -2.8847,  -3.0576]],\n",
       "\n",
       "        [[ -0.5904,  -4.9699,   6.2472],\n",
       "         [ -4.9699,   0.7071,   1.4893],\n",
       "         [  6.2472,   1.4893,  -6.5298]],\n",
       "\n",
       "        [[ -4.3907,  -2.5681,   3.5522],\n",
       "         [ -2.5681,  -7.3312,   5.6401],\n",
       "         [  3.5522,   5.6401,  -9.5455]],\n",
       "\n",
       "        [[  4.5836,   6.9426,  -9.3565],\n",
       "         [  6.9426,  16.6266, -19.8825],\n",
       "         [ -9.3565, -19.8824,  24.6431]],\n",
       "\n",
       "        [[ -7.6125,   0.0429,   7.3945],\n",
       "         [  0.0429,  -5.7897,   5.1535],\n",
       "         [  7.3945,   5.1535,  -9.7995]],\n",
       "\n",
       "        [[ -4.4861,  -1.5759,   4.3393],\n",
       "         [ -1.5759,  -1.8095,   0.4485],\n",
       "         [  4.3393,   0.4485,  -0.0765]],\n",
       "\n",
       "        [[  2.8892,   9.1988, -10.8065],\n",
       "         [  9.1988,   7.0479, -17.1685],\n",
       "         [-10.8065, -17.1685,  21.4411]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.batch_hessian(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
